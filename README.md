# DH-FaceVid-1K
Human-centric generative models are becoming increas-
ingly popular, giving rise to various innovative tools and
applications, such as talking face videos conditioned on text
or audio prompts. The core of these capabilities lies in pow-
erful pretrained foundation models, trained on large-scale,
high-quality datasets. However, many advanced methods
rely on in-house data subject to various constraints, and
other current studies fail to generate high-resolution face
videos, which is mainly attributed to the significant lack of
large-scale, high-quality face video datasets. In this pa-
per, we introduce a human face video dataset, DH-FaceVid-
1K. Our collection spans 1200 hours in total, encompass-
ing 270,043 video samples from over 20,000 individuals.
Each sample includes corresponding speech audio, facial
keypoints, and text annotations. Compared to other pub-
licly available datasets, ours distinguishes itself through its
multi-ethnic coverage and high-quality comprehensive in-
dividual attributes. We establish multiple face video gen-
eration models supporting tasks such as text-to-video and
image-to-video generation. In addition, we develop com-
prehensive benchmarks to validate the scaling law when us-
ing different proportions of our dataset. Our primary aim is
to contribute a face video dataset, particularly addressing
the underrepresentation of Asian faces in existing curated
datasets and thereby enriching the global spectrum of face-
centric data and mitigating demographic biases.


If you find FaceVid-1K useful for your work please cite:
```
@inproceedings{Di2024FaceVid1KAL,
      title={FaceVid-1K: A Large-Scale High-Quality Multiracial Human Face Video Dataset},
      author={Donglin Di and He Feng and Wenzhang Sun and Yongjia Ma and Hao Li and Wei Chen and Xiaofei Gou and Tonghua Su and Xun Yang},
      year={2024},
      url={https://api.semanticscholar.org/CorpusID:273233717}
}
```

# Website License
<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
